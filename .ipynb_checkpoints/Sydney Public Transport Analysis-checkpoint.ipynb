{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88eb95f-d613-4055-a597-168645c5cf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
       "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
    "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898cf38e-9112-4a9c-88f3-a14aadcf2fd0",
   "metadata": {},
   "source": [
    "# 👥 Group Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef020f-e468-413a-9bc8-95caffe92d90",
   "metadata": {},
   "source": [
    "<p><strong>Code Language:</strong> <span style=\"font-size:18px;\">Python</span></p>\n",
    "\n",
    "<table style=\"font-size:18px;\">\n",
    "  <tr>\n",
    "    <th>Name</th>\n",
    "    <th>SID</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Ngoc Minh Dao</td>\n",
    "    <td>520577590</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Manh Duc Nguyen</td>\n",
    "    <td>520561337</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2045e90-d8d3-4777-b82b-f685450eec3e",
   "metadata": {},
   "source": [
    "# Sydney Public Transport Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795c0e1-3603-4a6c-8f65-6819761f6ac4",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4dd5bc-cfc0-44b0-ba1c-eadff508e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for spatial data\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "\n",
    "# Imports for pgadmin\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2638eeed-0e2c-4e8f-a9a0-b1ef025609b5",
   "metadata": {},
   "source": [
    "### Connect to pgAdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37efdfa2-37ec-42ab-a033-cc814a56bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        port       = db_conn_dict['port']\n",
    "        try:\n",
    "            db = create_engine(f'postgresql+psycopg2://{db_user}:{db_pw}@{host}:{port}/{default_db}', echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(text(sqlcmd), args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c4d11b-8999-44be-a81f-dd390f0ac326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully.\n"
     ]
    }
   ],
   "source": [
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f24cb-70fd-4c30-a320-127a88b08649",
   "metadata": {},
   "source": [
    "### SRID Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d01651f-b52c-4842-a76d-29f6c36e3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "srid = 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20241aad-1628-4193-bb85-7ab6a8d1cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wkt_element(geom, srid):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a1d28-a7ca-4abf-bcd2-00478232b4c6",
   "metadata": {},
   "source": [
    "## Task 1: Import and Clean datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3bf61-cc3f-4db8-89a2-a4e2ce96b157",
   "metadata": {},
   "source": [
    "### 1.1 Load + clean Sydney Trains data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1472e5-60fb-4f96-a5f0-5ad2bbb55755",
   "metadata": {},
   "source": [
    "#### 1.1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f052fc7c-c9f2-48b6-ad33-d8403fd45afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['objectid', 'shape_id', 'route_id', 'agency_id', 'route_shor',\n",
      "       'route_long', 'route_desc', 'route_type', 'route_colo', 'route_text',\n",
      "       'exact_time', 'route_ty00', 'st_length(', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the file\n",
    "trains = gpd.read_file(\"SydneyTrainRoutes/sydneytrains/SydneyTrains.shp\")\n",
    "print(trains.columns)\n",
    "# trains.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a75b70-04a9-4cbf-b2c3-6869dc41a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the Sydney trains\n",
    "sydney_trains = trains[trains[\"agency_id\"].str.startswith(\"Sydney\")]\n",
    "# sydney_trains.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81843661-b320-45ce-b875-665ade2b00c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objectid         int64\n",
       "shape_id        object\n",
       "route_id        object\n",
       "agency_id       object\n",
       "route_shor      object\n",
       "route_long      object\n",
       "route_desc      object\n",
       "route_type      object\n",
       "route_colo      object\n",
       "route_text      object\n",
       "exact_time      object\n",
       "route_ty00      object\n",
       "st_length(     float64\n",
       "geometry      geometry\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "sydney_trains.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72c20a-b834-4fd9-838e-b969e017b8a6",
   "metadata": {},
   "source": [
    "#### 1.1.2 SRID Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555a8401-06db-42f4-a089-6c172516b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_trains = sydney_trains.copy()  # creating a copy of the original for later\n",
    "sydney_trains['geom'] = sydney_trains['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))  # applying the function\n",
    "sydney_trains = sydney_trains.drop(columns=\"geometry\")  # deleting the old copy\n",
    "# sydney_trains.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72947524-d28f-4ee1-a7c8-7f37621bb192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "objectid       0\n",
      "shape_id       0\n",
      "route_id       0\n",
      "agency_id      0\n",
      "route_shor     0\n",
      "route_long     0\n",
      "route_desc     0\n",
      "route_type     0\n",
      "route_colo     0\n",
      "route_text     0\n",
      "exact_time    54\n",
      "route_ty00     0\n",
      "st_length(     0\n",
      "geom           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values \n",
    "null_val = sydney_trains.isnull().sum()\n",
    "print(f\"Missing values per column:\\n{null_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50b8dc93-8043-49a4-bda0-d49a505b5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"exact_time\", fill with \"Unknown\"\n",
    "sydney_trains['exact_time'] = sydney_trains['exact_time'].fillna('Unknown')\n",
    "# sydney_trains.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f56b4c-9b94-4599-b0ae-72e8df83ca26",
   "metadata": {},
   "source": [
    "#### 1.1.3 Create table for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e040ff8-4e6a-4cbd-bd61-6fb7a37c44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS sydney_trains;\n",
    "CREATE TABLE sydney_trains (\n",
    "    objectid     INTEGER PRIMARY KEY,\n",
    "    shape_id     VARCHAR(255),\n",
    "    route_id     VARCHAR(255),\n",
    "    agency_id    VARCHAR(255),\n",
    "    route_shor   VARCHAR(255),\n",
    "    route_long   VARCHAR(255),\n",
    "    route_desc   VARCHAR(255),\n",
    "    route_type   VARCHAR(255),\n",
    "    route_colo   VARCHAR(255),\n",
    "    route_text   VARCHAR(255),\n",
    "    exact_time   VARCHAR(255),\n",
    "    route_ty00   VARCHAR(255),\n",
    "    st_length    DOUBLE PRECISION,\n",
    "    geom         GEOMETRY(LINESTRING, 4326)\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c5680-2183-4b15-a876-f41580642c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_trains.to_sql(\n",
    "    'sydney_trains', conn, if_exists='append', index=False, dtype={'geom': Geometry('LINESTRING', srid)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eef9c4-6cf0-43d2-b6e6-278e73875f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Create a spatial index on the 'geom' column for efficient spatial queries\n",
    "conn.execute(text(\"\"\"\n",
    "CREATE INDEX idx_geom ON sydney_trains USING GIST (geom);\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab3249-004d-4c03-84a2-85bd2d0bf2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn, \"SELECT * FROM sydney_trains LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae39b41-124d-4980-9c04-c9644026e99f",
   "metadata": {},
   "source": [
    "### 1.2 Load + clean Train Station Entrance Locations data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8bcb3-2066-4db9-899c-15f280103acb",
   "metadata": {},
   "source": [
    "#### 1.2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e75a89-1eba-4afc-bd72-a42b067e4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file\n",
    "entrance_loc = pd.read_csv(\"TrainStationEntranceLocations/stationentrances2020_v4.csv\")\n",
    "entrance_loc.columns = [col.lower() for col in entrance_loc.columns]\n",
    "print(entrance_loc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e8bbd-b3f7-4a37-a6fa-13541726ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "entrance_loc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9634638d-ff39-4735-ad41-87af7a7f57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values \n",
    "null_val = entrance_loc.isnull().sum()\n",
    "print(f\"Missing values per column:\\n{null_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e672939-1104-47ac-8bf2-37646689b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Street_Type, fill with \"Unknown\"\n",
    "entrance_loc['Street_Type'] = entrance_loc['Street_Type'].fillna('Unknown')\n",
    "# For Exit_Number, assuming missing = 0 exits\n",
    "entrance_loc['Exit_Number'] = entrance_loc['Exit_Number'].fillna(0).astype(int)\n",
    "entrance_loc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f626d1f-3d01-4615-8afa-3201c8e8c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrance_loc['geom'] = gpd.points_from_xy(entrance_loc.LONG, entrance_loc.LAT)      # creating the geometry column\n",
    "entrance_loc = entrance_loc.drop(columns = ['LONG', 'LAT'])        # removing the old latitude/longitude fields\n",
    "entrance_loc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111b244-2db7-49e6-a7d1-cd6299c92247",
   "metadata": {},
   "source": [
    "#### 1.2.2 SRID Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aedddc0-7d6f-43d4-8158-546f454b9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrance_loc['geom'] = entrance_loc['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))\n",
    "entrance_loc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb6b64-6262-49d3-82df-039f37cd3a1a",
   "metadata": {},
   "source": [
    "#### 1.2.3 Create table for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eca232-fef3-4f5c-88d2-3585b20b655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS train_entrance;\n",
    "CREATE TABLE train_entrance (\n",
    "    train_station  VARCHAR(255),\n",
    "    street_name    VARCHAR(255),\n",
    "    street_type    VARCHAR(255),\n",
    "    entrance_type  VARCHAR(255),\n",
    "    exit_number    INTEGER,\n",
    "    geom           GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef1a50-91f6-4f55-8d6d-0fc00380c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_entrance.to_sql('train_entrance', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab0acf-6255-41d9-96d4-1ca32268f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index on the 'geom' column\n",
    "conn.execute(text(\"\"\"\n",
    "CREATE INDEX idx_entrance_geom ON train_entrance USING GIST(geom);\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46defd92-22ef-45f2-84d2-86837e71040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn, \"SELECT * FROM train_entrance LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6190fea-48d9-4b86-8cfa-6437c1e3b4ad",
   "metadata": {},
   "source": [
    "### 1.3 Load + clean Train Station Entries Exits data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d3978-4749-4c7a-aa42-b8f414ce1725",
   "metadata": {},
   "source": [
    "#### 1.3.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa89e0a-9530-4833-8740-50aa5f69c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file\n",
    "entries_exit = pd.read_csv(\"TrainStationEntriesExits/train-station-entries-exits-data-may-2025.csv\")\n",
    "entries_exit.columns = [col.lower() for col in entries_exit.columns]\n",
    "print(entries_exit.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02b0f6-95da-4af9-9ce8-e5a1bbe061a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "entries_exit.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b80da-7d2a-4b26-b602-1b6a7ec092ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MonthYear to date\n",
    "entries_exit['year_month'] = pd.to_datetime(entries_exit['MonthYear'], format='%Y-%m', errors='coerce')\n",
    "entries_exit.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5d143-05e5-4382-a41b-e0d51cba0c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values \n",
    "null_val = entries_exit.isnull().sum()\n",
    "print(f\"Missing values per column:\\n{null_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836d72e-dff5-4a9b-b14c-a902c36dcc89",
   "metadata": {},
   "source": [
    "#### 1.3.2 Create table for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c2263-5fa6-4da8-b3a9-f45562b1baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS train_entry_exit;\n",
    "CREATE TABLE train_entry_exit (\n",
    "    year_month    DATE,\n",
    "    station       VARCHAR(255),\n",
    "    station_type  VARCHAR(255),\n",
    "    entry_exit    VARCHAR(50),\n",
    "    trip_count    INTEGER\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bf7ef-ab1a-4f88-8140-fefe9c2d5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_entry_exit.to_sql(\"train_entry_exit\", conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab08799-3fbf-4a41-b0f9-82a3e3dcaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn,\"SELECT * FROM train_entry_exit LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5893741-e45d-43be-9b23-8001c5cbbb53",
   "metadata": {},
   "source": [
    "### 1.4 Load + clean Opal Patronage data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60528ac-7ba1-4e4c-b4c8-c810dd2a72d8",
   "metadata": {},
   "source": [
    "#### 1.4.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd504e-a9dc-4e0f-80ee-8a8b67a35c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# 1. Find all Opal_Patronage files\n",
    "file_pattern = \"OpalPatronage/Opal_Patronage_202*.txt\"\n",
    "file_list = glob.glob(file_pattern)\n",
    "print(f\"Found {len(file_list)} files:\")\n",
    "# for f in file_list:\n",
    "#     print(\" \", f)\n",
    "\n",
    "# 2. Read, clean & trim empty columns in each file\n",
    "dfs = []\n",
    "for fname in file_list:\n",
    "    df = pd.read_csv(\n",
    "        fname,\n",
    "        sep=\"|\",\n",
    "        # na_values=[\"<50\"],        # convert \"<50\" to NaN\n",
    "        parse_dates=[\"trip_origin_date\"]\n",
    "    )\n",
    "    # Drop any column that’s entirely NaN in this file\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    dfs.append(df)\n",
    "\n",
    "# 3. Concatenate into one DataFrame\n",
    "if not dfs:\n",
    "    raise FileNotFoundError(f\"No files matched pattern: {file_pattern}\")\n",
    "full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 4. Inspect the result\n",
    "print(\"\\nCombined DataFrame shape:\", full_df.shape)\n",
    "display(full_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74fa77-c5e0-47a8-9205-27972fb3c89f",
   "metadata": {},
   "source": [
    "#### 1.4.2 Clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aab5bc-dd92-4646-b479-0835dfdbe2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute '<50' as NaN, convert to numeric, then median‐impute\n",
    "# Mark '<50' as missing\n",
    "full_df['Tap_Ons']  = full_df['Tap_Ons'].replace('<50', pd.NA)\n",
    "full_df['Tap_Offs'] = full_df['Tap_Offs'].replace('<50', pd.NA)\n",
    "\n",
    "# Convert to numeric\n",
    "full_df['Tap_Ons']  = pd.to_numeric(full_df['Tap_Ons'],  errors='coerce')\n",
    "full_df['Tap_Offs'] = pd.to_numeric(full_df['Tap_Offs'], errors='coerce')\n",
    "\n",
    "# Compute medians\n",
    "med_on  = int(full_df['Tap_Ons'].median())\n",
    "med_off = int(full_df['Tap_Offs'].median())\n",
    "\n",
    "# Fill missing with medians\n",
    "full_df['Tap_Ons']  = full_df['Tap_Ons'].fillna(med_on).astype(int)\n",
    "full_df['Tap_Offs'] = full_df['Tap_Offs'].fillna(med_off).astype(int)\n",
    "\n",
    "# Confirm no more missing\n",
    "print(\"Missing Tap_Ons after imputation:\", full_df['Tap_Ons'].isna().sum())\n",
    "print(\"Missing Tap_Offs after imputation:\", full_df['Tap_Offs'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea39d4b-9d40-4d0c-95dd-1f06bba9f41b",
   "metadata": {},
   "source": [
    "#### 1.4.3 Create table for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e637c4c-6bf0-4a28-a94e-151ebdc18188",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS opal_patronage;\n",
    "CREATE TABLE opal_patronage (\n",
    "    trip_origin_date DATE,\n",
    "    mode_name        VARCHAR(255),\n",
    "    ti_region        VARCHAR(255),\n",
    "    tap_hour         SMALLINT,\n",
    "    tap_ons          INTEGER,\n",
    "    tap_offs         INTEGER\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865a2d9-0365-4419-9bd3-fcfb024c2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned DataFrame into SQL\n",
    "# Prepare DataFrame\n",
    "to_sql_df = full_df[['trip_origin_date','mode_name','ti_region','tap_hour','Tap_Ons','Tap_Offs']].copy()\n",
    "to_sql_df.columns = ['trip_origin_date','mode_name','ti_region','tap_hour','tap_ons','tap_offs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47220d-559a-40e9-9538-595a0785edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to SQL\n",
    "to_sql_df.to_sql(\"opal_patronage\", conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea08a7-be3b-4032-a2ed-e561d14112e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn,\"SELECT * FROM opal_patronage LIMIT 5;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
